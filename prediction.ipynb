{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (20,10) # width, height in inches\n",
    "\n",
    "# Load the CSV file\n",
    "df1 = pd.read_csv('C:\\\\Users\\\\HP\\\\Downloads\\\\House-Price-Prediction-Project\\\\Bengaluru_House_Data.csv')\n",
    "df1.head()\n",
    "\n",
    "# Get the no of rows and columns\n",
    "df1.shape\n",
    "\n",
    "# Get all the column names\n",
    "df1.columns\n",
    "\n",
    "# Lets check the unique values 'area_type' column\n",
    "df1.area_type.unique()\n",
    "\n",
    "# Let get the count of training examples for each area type\n",
    "df1.area_type.value_counts()\n",
    "\n",
    "# Note everytime we make change in dataset we store it in new dataframe\n",
    "df2 = df1.drop(['area_type', 'availability', 'society', 'balcony'], axis='columns')\n",
    "\n",
    "print('Rows and columns are = ', df2.shape)\n",
    "df2.head()\n",
    "\n",
    "# Get the sum of all na values from dataset\n",
    "df2.isna().sum()\n",
    "\n",
    "df3 = df2.dropna()\n",
    "df3.isnull().sum()\n",
    "\n",
    "# Since all training examples containing null values are dropped lets check the shape of the dataset again\n",
    "df3.shape\n",
    "\n",
    "df3['size'].unique()\n",
    "\n",
    "df4 = df3.copy()\n",
    "\n",
    "# Using lambda function we can get the BHK numeric value\n",
    "df4['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df4.bhk.unique()\n",
    "\n",
    "# Get the training examples with home size more than 20 BHK\n",
    "df4[df4.bhk > 20]\n",
    "\n",
    "df4.total_sqft.unique()\n",
    "\n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Test the function\n",
    "print('is this (123) float value = %s' % (is_float(123)))\n",
    "print('is this (1133 - 1384) float value = %s' % (is_float('1133 - 1384')))\n",
    "\n",
    "# Showing training examples where 'total_sqft' value is not float\n",
    "df4[~df4['total_sqft'].apply(is_float)].head(10)\n",
    "\n",
    "def convert_range_to_sqft(x):\n",
    "    try:\n",
    "        tokens = x.split('-')\n",
    "        if len(tokens) == 2:\n",
    "            return (float(tokens[0]) + float(tokens[1])) / 2\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Testing the function\n",
    "print('converting range to sq feet = %s' % (convert_range_to_sqft('1233 - 1445')))\n",
    "print('converting range to sq feet = %s' % (convert_range_to_sqft('1333')))\n",
    "print('converting range to sq feet = %s' % (convert_range_to_sqft('1333.3')))\n",
    "print('converting range to sq feet = %s' % (convert_range_to_sqft(3333.3)))\n",
    "\n",
    "# Now we apply the conversion function to 'total_sqft' column\n",
    "df5 = df4.copy()\n",
    "df5['total_sqft'] = df5['total_sqft'].apply(convert_range_to_sqft)\n",
    "\n",
    "# Get training examples with invalid values for 'total_sqft'\n",
    "df5.loc[30]\n",
    "\n",
    "# Lets check our dataset again\n",
    "df5.head()\n",
    "\n",
    "df5.total_sqft.unique()\n",
    "\n",
    "# Get the training examples where total_sqft is not numeric\n",
    "df5[~df5['total_sqft'].apply(is_float)].head(10)\n",
    "\n",
    "df6 = df5.copy()\n",
    "\n",
    "# Removing outliers\n",
    "df6['price_per_sqft'] = df6['price']*100000 / df6['total_sqft']\n",
    "\n",
    "# Corrected function for removing outliers based on price_per_sqft\n",
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf['price_per_sqft'])\n",
    "        st = np.std(subdf['price_per_sqft'])\n",
    "        reduced_df = subdf[(subdf['price_per_sqft'] > (m - st)) & (subdf['price_per_sqft'] <= (m + st))]\n",
    "        df_out = pd.concat([df_out, reduced_df], ignore_index=True)\n",
    "    return df_out\n",
    "\n",
    "# Applying the function after calculating price_per_sqft\n",
    "df7 = remove_pps_outliers(df6)\n",
    "df7.shape\n",
    "\n",
    "# Checking data after removing outliers for price_per_sqft\n",
    "df7.head()\n",
    "\n",
    "def plot_scatter_chart(df, location):\n",
    "    bhk2 = df[(df.location == location) & (df.bhk == 2)]\n",
    "    bhk3 = df[(df.location == location) & (df.bhk == 3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15, 10)\n",
    "    plt.scatter(bhk2.total_sqft, bhk2.price, color='blue', label='2 BHK', s=50)\n",
    "    plt.scatter(bhk3.total_sqft, bhk3.price, color='green', label='3 BHK', s=50)\n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "\n",
    "plot_scatter_chart(df7, \"Rajaji Nagar\")\n",
    "\n",
    "plot_scatter_chart(df7, \"Hebbal\")\n",
    "\n",
    "# Remove bhk outliers\n",
    "def remove_bhk_outliers(df):\n",
    "    exclude_indices = np.array([])\n",
    "    for location, location_df in df.groupby('location'):\n",
    "        bhk_stats = {}\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean': np.mean(bhk_df['price_per_sqft']),\n",
    "                'std': np.std(bhk_df['price_per_sqft']),\n",
    "                'count': bhk_df.shape[0]\n",
    "            }\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            stats = bhk_stats.get(bhk - 1)\n",
    "            if stats and stats['count'] > 5:\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df['price_per_sqft'] < (stats['mean'])].index.values)\n",
    "    return df.drop(exclude_indices, axis='index')\n",
    "\n",
    "# Applying the function\n",
    "df8 = remove_bhk_outliers(df7)\n",
    "df8.shape\n",
    "\n",
    "# Checking data after removing outliers for BHK\n",
    "df8.head()\n",
    "\n",
    "# Get the plotting function for plotting histogram for price_per_sqft\n",
    "def plot_histogram(df):\n",
    "    matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    plt.hist(df['price_per_sqft'], rwidth=0.8, bins=20)\n",
    "    plt.xlabel(\"Price Per Square Feet\")\n",
    "    plt.ylabel(\"Count\")\n",
    "\n",
    "plot_histogram(df8)\n",
    "\n",
    "# We will be using one hot encoding for location\n",
    "\n",
    "df9 = df8.copy()\n",
    "\n",
    "df9['location'] = df9.location.apply(lambda x: x.strip())\n",
    "location_stats = df9['location'].value_counts(ascending=False)\n",
    "location_stats\n",
    "\n",
    "# For checking the location with 10 or less training examples\n",
    "location_stats[location_stats <= 10]\n",
    "\n",
    "# Put location with less than 10 examples in other category\n",
    "location_stats_less_than_10 = location_stats[location_stats <= 10]\n",
    "location_stats_less_than_10\n",
    "\n",
    "# New location feature where location with less than 10 examples is converted to other category\n",
    "df9.location = df9.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)\n",
    "df9.head(10)\n",
    "\n",
    "# Check the new location count\n",
    "len(df9.location.unique())\n",
    "\n",
    "# Lets check the data after removing outliers\n",
    "df9.head()\n",
    "\n",
    "# Since we have to implement machine learning we must convert our training examples into numeric\n",
    "# We will use the pandas get_dummies method to convert the location into one hot encoding values\n",
    "dummies = pd.get_dummies(df9['location'])\n",
    "dummies.head(10)\n",
    "\n",
    "# For easy implementation we will concatenate dummies into df10\n",
    "df10 = pd.concat([df9, dummies.drop('other', axis='columns')], axis='columns')\n",
    "\n",
    "df10.head()\n",
    "\n",
    "# Dropping the location column since we no longer need it\n",
    "df10 = df10.drop('location', axis='columns')\n",
    "\n",
    "df10.head(2)\n",
    "\n",
    "df10.shape\n",
    "\n",
    "X = df10.drop(['price', 'size'], axis='columns')\n",
    "X.head()\n",
    "\n",
    "y = df10.price\n",
    "y.head()\n",
    "\n",
    "# Splitting the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_clf.score(X_test, y_test)\n",
    "\n",
    "# Use K fold cross validation to measure accuracy of our LinearRegression model\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)\n",
    "\n",
    "# Find best model using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def find_best_model_using_gridsearchcv(X, y):\n",
    "    algos = {\n",
    "        'linear_regression': {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'normalize': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1, 2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion': ['mse', 'friedman_mse'],\n",
    "                'splitter': ['best', 'random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "    for algo_name, config in algos.items():\n",
    "        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X, y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "\n",
    "find_best_model_using_gridsearchcv(X, y)\n",
    "\n",
    "def predict_price(location, sqft, bath, bhk):\n",
    "    loc_index = np.where(X.columns == location)[0][0]\n",
    "\n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = sqft\n",
    "    x[1] = bath\n",
    "    x[2] = bhk\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "\n",
    "    return lr_clf.predict([x])[0]\n",
    "\n",
    "predict_price('1st Phase JP Nagar', 1000, 2, 2)\n",
    "\n",
    "predict_price('1st Phase JP Nagar', 1000, 3, 3)\n",
    "\n",
    "predict_price('Indira Nagar', 1000, 2, 2)\n",
    "\n",
    "predict_price('Indira Nagar', 1000, 3, 3)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('Real_Estate_Price_Prediction_Project.pickle', 'wb') as f:\n",
    "    pickle.dump(lr_clf, f)\n",
    "\n",
    "import json\n",
    "columns = {\n",
    "    'data_columns': [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\", \"w\") as f:\n",
    "    f.write(json.dumps(columns))\n",
    "\n",
    "print(\"Model and columns JSON saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
